@article{p49,
  journal = {IEEE TVCG},
  year = 2015,
  title = {AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics},
  doi = {10.1109/TVCG.2015.2467434},
  url = {http://dx.doi.org/10.1109/TVCG.2015.2467434},
  author = {Byska, J. and Le Muzic, M. and Groller, E. and Viola, I. and Kozlikova, B.},
  pages = {747--756},
  keywords = {Protein, tunnel, molecular dynamics, aggregation, interaction},
  abstract = {In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included.},
}
@article{p74,
  journal = {IEEE TVCG},
  year = 2015,
  title = {JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure},
  doi = {10.1109/TVCG.2015.2467331},
  url = {http://dx.doi.org/10.1109/TVCG.2015.2467331},
  author = {Labschütz, M. and Bruckner, S. and Groller, E. and Hadwiger, M. and Rautek, P.},
  pages = {1025--1034},
  keywords = {Data Transformation and Representation, GPUs and Multi-core Architectures, Volume Rendering},
  abstract = {Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.},
}
@misc{p117,
  year = 2015,
  title = {Interactive semi-automatic categorization for spinel group minerals},
  doi = {10.1109/VAST.2015.7347676},
  url = {http://dx.doi.org/10.1109/VAST.2015.7347676},
  author = {Lujan Ganuza, M. and Gargiulo, F. and Ferracutti, G. and Castro, S. and Bjerg, E. and Groller, E. and Matkovic, K.},
  pages = {197--198},
  keywords = {},
  abstract = {Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist's workflow significantly.},
}
@article{p123,
  journal = {IEEE TVCG},
  year = 2015,
  title = {LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design},
  doi = {10.1109/TVCG.2015.2468011},
  url = {http://dx.doi.org/10.1109/TVCG.2015.2468011},
  author = {Sorger, J. and Ortner, T. and Luksch, C. and Schwärzler, M. and Groller, E. and Piringer, H.},
  pages = {290--299},
  keywords = {Integrating Spatial and Non-Spatial Data Visualization, Visualization in Physical Sciences and Engineering, Coordinated and Multiple Views, Visual Knowledge Discovery},
  abstract = {State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty.},
}
@article{p235,
  journal = {IEEE TVCG},
  year = 2014,
  title = {ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization},
  doi = {10.1109/TVCG.2014.2346318},
  url = {http://dx.doi.org/10.1109/TVCG.2014.2346318},
  author = {Rautek, P. and Bruckner, S. and Groller, E. and Hadwiger, M.},
  pages = {2388--2396},
  keywords = {Domain-specific languages, Volume visualization, Volume visualization framework},
  abstract = {Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.},
}
@inproceedings{p250,
  booktitle = {Proc. VAST},
  year = 2014,
  title = {BoundarySeer: Visual Analysis of 2D Boundary Changes},
  doi = {10.1109/VAST.2014.7042490},
  url = {http://dx.doi.org/10.1109/VAST.2014.7042490},
  author = {Wenchao Wu and Yixian Zheng and Huamin Qu and Wei Chen and Groller, E. and Lionel Ni},
  pages = {143--152},
  keywords = {Boundary change, visual analytics, scatter plot, ThemeRiver, contour map, radial visualization},
  abstract = {Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system.},
}
@article{p252,
  journal = {IEEE TVCG},
  year = 2014,
  title = {Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees},
  doi = {10.1109/TVCG.2014.2346626},
  url = {http://dx.doi.org/10.1109/TVCG.2014.2346626},
  author = {Beham, M. and Herzner, W. and Groller, E. and Kehrer, J.},
  pages = {1693--1702},
  keywords = {Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis},
  abstract = {Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.},
}
@article{p273,
  journal = {IEEE TVCG},
  year = 2014,
  title = {Run Watchers: Automatic Simulation-Based Decision Support in Flood Management},
  doi = {10.1109/TVCG.2014.2346930},
  url = {http://dx.doi.org/10.1109/TVCG.2014.2346930},
  author = {Konev, A. and Waser, J. and Sadransky, B. and Cornel, D. and Perdigao, R.A.P. and Horvath, Z. and Groller, E.},
  pages = {1873--1882},
  keywords = {Disaster management, simulation control, decision making, visual evidence, storytelling},
  abstract = {In this paper, we introduce a simulation-based approach to design protection plans for flood events. Existing solutions require a lot of computation time for an exhaustive search, or demand for a time-consuming expert supervision and steering. We present a faster alternative based on the automated control of multiple parallel simulation runs. Run Watchers are dedicated system components authorized to monitor simulation runs, terminate them, and start new runs originating from existing ones according to domain-specific rules. This approach allows for a more efficient traversal of the search space and overall performance improvements due to a re-use of simulated states and early termination of failed runs. In the course of search, Run Watchers generate large and complex decision trees. We visualize the entire set of decisions made by Run Watchers using interactive, clustered timelines. In addition, we present visualizations to explain the resulting response plans. Run Watchers automatically generate storyboards to convey plan details and to justify the underlying decisions, including those which leave particular buildings unprotected. We evaluate our solution with domain experts.},
}
@article{p276,
  journal = {IEEE TVCG},
  year = 2014,
  title = {The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals},
  doi = {10.1109/TVCG.2014.2346754},
  url = {http://dx.doi.org/10.1109/TVCG.2014.2346754},
  author = {Lujan Ganuza, M. and Ferracutti, G. and Gargiulo, M.F. and Castro, S. and Bjerg, E. and Groller, E. and Matkovic, K.},
  pages = {1913--1922},
  keywords = {Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies},
  abstract = {Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the cur- ent workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.},
}
@inproceedings{p295,
  booktitle = {Proc. VAST},
  year = 2014,
  title = {YMCA - Your Mesh Comparison Application},
  doi = {10.1109/VAST.2014.7042491},
  url = {http://dx.doi.org/10.1109/VAST.2014.7042491},
  author = {Schmidt, J. and Preiner, R. and Auzinger, T. and Wimmer, T. and Groller, E. and Bruckner, S.},
  pages = {153--162},
  keywords = {Visual analysis, comparative visualization, 3D data exploration, focus+context, mesh comparison},
  abstract = {Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.},
}
@article{p298,
  journal = {IEEE TVCG},
  year = 2013,
  title = {A Model for Structure-Based Comparison of Many Categories in Small-Multiple Displays},
  doi = {10.1109/TVCG.2013.122},
  url = {http://dx.doi.org/10.1109/TVCG.2013.122},
  author = {Kehrer, J. and Piringer, H. and Berger, W. and Groller, E.},
  pages = {2287--2296},
  keywords = {Comparative visualization, small-multiple displays, trellis displays, categorical data},
  abstract = {Many application domains deal with multi-variate data that consist of both categorical and numerical information. Small-multiple displays are a powerful concept for comparing such data by juxtaposition. For comparison by overlay or by explicit encoding of computed differences, however, a specification of references is necessary. In this paper, we present a formal model for defining semantically meaningful comparisons between many categories in a small-multiple display. Based on pivotized data that are hierarchically partitioned by the categories assigned to the x and y axis of the display, we propose two alternatives for structure-based comparison within this hierarchy. With an absolute reference specification, categories are compared to a fixed reference category. With a relative reference specification, in contrast, a semantic ordering of the categories is considered when comparing them either to the previous or subsequent category each. Both reference specifications can be defined at multiple levels of the hierarchy (including aggregated summaries), enabling a multitude of useful comparisons. We demonstrate the general applicability of our model in several application examples using different visualizations that compare data by overlay or explicit encoding of differences.},
}
@article{p359,
  journal = {IEEE TVCG},
  year = 2013,
  title = {MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data},
  doi = {10.1109/TVCG.2013.177},
  url = {http://dx.doi.org/10.1109/TVCG.2013.177},
  author = {Reh, A. and Gusenbauer, C. and Kastner, J. and Groller, E. and Heinzl, C.},
  pages = {2906--2915},
  keywords = {3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects},
  abstract = {This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.},
}
@article{p363,
  journal = {IEEE TVCG},
  year = 2013,
  title = {Vessel Visualization using Curved Surface Reformation},
  doi = {10.1109/TVCG.2013.215},
  url = {http://dx.doi.org/10.1109/TVCG.2013.215},
  author = {Auzinger, T. and Mistelbauer, G. and Baclija, I. and Schernthaner, R. and Kochl, A. and Wimmer, M. and Groller, E. and Bruckner, S.},
  pages = {2858--2867},
  keywords = {Reformation, volume rendering, surface approximation},
  abstract = {Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.},
}
@article{p390,
  journal = {IEEE TVCG},
  year = 2013,
  title = {VAICo: Visual Analysis for Image Comparison},
  doi = {10.1109/TVCG.2013.213},
  url = {http://dx.doi.org/10.1109/TVCG.2013.213},
  author = {Schmidt, J. and Groller, E. and Bruckner, S.},
  pages = {2090--2099},
  keywords = {Comparative visualization, focus+context visualization, image set comparison},
  abstract = {Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.},
}
@article{p470,
  journal = {IEEE TVCG},
  year = 2012,
  title = {Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data},
  doi = {10.1109/TVCG.2012.254},
  url = {http://dx.doi.org/10.1109/TVCG.2012.254},
  author = {Alsallakh, B. and Aigner, W. and Miksch, S. and Groller, E.},
  pages = {2849--2858},
  keywords = {Large categorical data, contingency table analysis, information interfaces and representation, visual analytics},
  abstract = {Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson's residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.},
}
@inproceedings{p474,
  booktitle = {Proc. VAST},
  year = 2012,
  title = {Smart super views---A knowledge-assisted interface for medical visualization},
  doi = {10.1109/VAST.2012.6400555},
  url = {http://dx.doi.org/10.1109/VAST.2012.6400555},
  author = {Mistelbauer, G. and Bouzari, H. and Schernthaner, R. and Baclija, I. and Kochl, A. and Bruckner, S. and Sramek, M. and Groller, E.},
  pages = {163--172},
  keywords = {Visualization, Fuzzy Logic, Interaction},
  abstract = {Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.},
}
@article{p525,
  journal = {IEEE TVCG},
  year = 2012,
  title = {Sketching Uncertainty into Simulations},
  doi = {10.1109/TVCG.2012.261},
  url = {http://dx.doi.org/10.1109/TVCG.2012.261},
  author = {Ribicic, H. and Waser, J. and Gurbat, R. and Sadransky, B. and Groller, E.},
  pages = {2255--2264},
  keywords = {Emergency/disaster management, interaction design, uncertainty visualization, sketch-based steering, ensemble simulation steering, integrated visualization system, flood management},
  abstract = {In a variety of application areas, the use of simulation steering in decision making is limited at best. Research focusing on this problem suggests that most user interfaces are too complex for the end user. Our goal is to let users create and investigate multiple, alternative scenarios without the need for special simulation expertise. To simplify the specification of parameters, we move from a traditional manipulation of numbers to a sketch-based input approach. Users steer both numeric parameters and parameters with a spatial correspondence by sketching a change onto the rendering. Special visualizations provide immediate visual feedback on how the sketches are transformed into boundary conditions of the simulation models. Since uncertainty with respect to many intertwined parameters plays an important role in planning, we also allow the user to intuitively setup complete value ranges, which are then automatically transformed into ensemble simulations. The interface and the underlying system were developed in collaboration with experts in the field of flood management. The real-world data they have provided has allowed us to construct scenarios used to evaluate the system. These were presented to a variety of flood response personnel, and their feedback is discussed in detail in the paper. The interface was found to be intuitive and relevant, although a certain amount of training might be necessary.},
}
@article{p671,
  journal = {IEEE TVCG},
  year = 2011,
  title = {Interactive Virtual Probing of 4D MRI Blood-Flow},
  doi = {10.1109/TVCG.2011.215},
  url = {http://dx.doi.org/10.1109/TVCG.2011.215},
  author = {van Pelt, R. and Olivan Bescos, J. and Breeuwer, M. and Clough, R.E. and Groller, E. and ter Haar Romenij, B. and Vilanova, A.},
  pages = {2153--2162},
  keywords = {Probing, Flow visualization, Illustrative visualization, Multivalued images, Phase-contrast cine MRI},
  abstract = {Better understanding of hemodynamics conceivably leads to improved diagnosis and prognosis of cardiovascular diseases. Therefore, an elaborate analysis of the blood-flow in heart and thoracic arteries is essential. Contemporary MRI techniques enable acquisition of quantitative time-resolved flow information, resulting in 4D velocity fields that capture the blood-flow behavior. Visual exploration of these fields provides comprehensive insight into the unsteady blood-flow behavior, and precedes a quantitative analysis of additional blood-flow parameters. The complete inspection requires accurate segmentation of anatomical structures, encompassing a time-consuming and hard-to-automate process, especially for malformed morphologies. We present a way to avoid the laborious segmentation process in case of qualitative inspection, by introducing an interactive virtual probe. This probe is positioned semi-automatically within the blood-flow field, and serves as a navigational object for visual exploration. The difficult task of determining position and orientation along the view-direction is automated by a fitting approach, aligning the probe with the orientations of the velocity field. The aligned probe provides an interactive seeding basis for various flow visualization approaches. We demonstrate illustration-inspired particles, integral lines and integral surfaces, conveying distinct characteristics of the unsteady blood-flow. Lastly, we present the results of an evaluation with domain experts, valuing the practical use of our probe and flow visualization techniques.},
}
@article{p672,
  journal = {IEEE TVCG},
  year = 2011,
  title = {Interactive Volume Visualization of General Polyhedral Grids},
  doi = {10.1109/TVCG.2011.216},
  url = {http://dx.doi.org/10.1109/TVCG.2011.216},
  author = {Muigg, P. and Hadwiger, M. and Doleisch, H. and Groller, E.},
  pages = {2115--2124},
  keywords = {Volume rendering, unstructured grids, polyhedral grids, GPU-based visualization},
  abstract = {This paper presents a novel framework for visualizing volumetric data specified on complex polyhedral grids, without the need to perform any kind of a priori tetrahedralization. These grids are composed of polyhedra that often are non-convex and have an arbitrary number of faces, where the faces can be non-planar with an arbitrary number of vertices. The importance of such grids in state-of-the-art simulation packages is increasing rapidly. We propose a very compact, face-based data structure for representing such meshes for visualization, called two-sided face sequence lists (TSFSL), as well as an algorithm for direct GPU-based ray-casting using this representation. The TSFSL data structure is able to represent the entire mesh topology in a 1D TSFSL data array of face records, which facilitates the use of efficient 1D texture accesses for visualization. In order to scale to large data sizes, we employ a mesh decomposition into bricks that can be handled independently, where each brick is then composed of its own TSFSL array. This bricking enables memory savings and performance improvements for large meshes. We illustrate the feasibility of our approach with real-world application results, by visualizing highly complex polyhedral data from commercial state-of-the-art simulation packages.},
}
@article{p677,
  journal = {IEEE TVCG},
  year = 2011,
  title = {Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations},
  doi = {10.1109/TVCG.2011.225},
  url = {http://dx.doi.org/10.1109/TVCG.2011.225},
  author = {Waser, J. and Ribicic, H. and Fuchs, R. and Hirsch, C. and Schindler, B. and Bloschl, G. and Groller, E.},
  pages = {1872--1881},
  keywords = {Emergency/Disaster Management, Visual Knowledge Discovery, Visualization System and Toolkit Design, Data-Flow, Meta-Flow, Parameter Study, Uncertainty, Visualization of Control},
  abstract = {Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.},
}
@article{p678,
  journal = {IEEE TVCG},
  year = 2011,
  title = {Projection-Based Metal-Artifact Reduction for Industrial 3D X-ray Computed Tomography},
  doi = {10.1109/TVCG.2011.228},
  url = {http://dx.doi.org/10.1109/TVCG.2011.228},
  author = {Amirkhanov, A. and Heinzl, C. and Reiter, M. and Kastner, J. and Groller, E.},
  pages = {2193--2202},
  keywords = {Metal-artifact reduction, multi-material components, visual analysis, 3D X-ray computed tomography},
  abstract = {Multi-material components, which contain metal parts surrounded by plastic materials, are highly interesting for inspection using industrial 3D X-ray computed tomography (3DXCT). Examples of this application scenario are connectors or housings with metal inlays in the electronic or automotive industry. A major problem of this type of components is the presence of metal, which causes streaking artifacts and distorts the surrounding media in the reconstructed volume. Streaking artifacts and dark-band artifacts around metal components significantly influence the material characterization (especially for the plastic components). In specific cases these artifacts even prevent a further analysis. Due to the nature and the different characteristics of artifacts, the development of an efficient artifact-reduction technique in reconstruction-space is rather complicated. In this paper we present a projection-space pipeline for metal-artifacts reduction. The proposed technique first segments the metal in the spatial domain of the reconstructed volume in order to separate it from the other materials. Then metal parts are forward-projected on the set of projections in a way that metal-projection regions are treated as voids. Subsequently the voids, which are left by the removed metal, are interpolated in the 2D projections. Finally, the metal is inserted back into the reconstructed 3D volume during the fusion stage. We present a visual analysis tool, allowing for interactive parameter estimation of the metal segmentation. The results of the proposed artifact-reduction technique are demonstrated on a test part as well as on real world components. For these specimens we achieve a significant reduction of metal artifacts, allowing an enhanced material characterization.},
}
@article{p692,
  journal = {IEEE TVCG},
  year = 2011,
  title = {Volume Analysis Using Multimodal Surface Similarity},
  doi = {10.1109/TVCG.2011.258},
  url = {http://dx.doi.org/10.1109/TVCG.2011.258},
  author = {Haidacher, M. and Bruckner, S. and Groller, E.},
  pages = {1969--1978},
  keywords = {Multimodal data, volume visualization, surface similarity},
  abstract = {The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.},
}
@article{p808,
  journal = {IEEE TVCG},
  year = 2010,
  title = {Exploration of 4D MRI Blood Flow using Stylistic Visualization},
  doi = {10.1109/TVCG.2010.153},
  url = {http://dx.doi.org/10.1109/TVCG.2010.153},
  author = {van Pelt, R. and Olivan Bescos, J. and Breeuwer, M. and Clough, R.E. and Groller, E. and ter Haar Romenij, B. and Vilanova, A.},
  pages = {1339--1347},
  keywords = {4D MRI blood-flow, Probing, Flow visualization, Illustrative visualization, Phase-contrast cine MRI},
  abstract = {Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.},
}
@article{p837,
  journal = {IEEE TVCG},
  year = 2010,
  title = {Visual Optimality and Stability Analysis of 3DCT Scan Positions},
  doi = {10.1109/TVCG.2010.214},
  url = {http://dx.doi.org/10.1109/TVCG.2010.214},
  author = {Amirkhanov, A. and Heinzl, C. and Reiter, M. and Groller, E.},
  pages = {1477--1486},
  keywords = {},
  abstract = {Industrial cone-beam X-Ray computed tomography (CT) systems often face problems due to artifacts caused by a bad placement of the specimen on the rotary plate. This paper presents a visual-analysis tool for CT systems, which provides a simulation-based preview and estimates artifacts and deviations of a specimen's placement using the corresponding 3D geometrical surface model as input. The presented tool identifies potentially good or bad placements of a specimen and regions of a specimen, which cause the major portion of artefacts. The tool can be used for a preliminary analysis of the specimen before CT scanning, in order to determine the optimal way of placing the object. The analysis includes: penetration lengths, placement stability and an investigation in Radon space. Novel visualization techniques are applied to the simulation data. A stability widget is presented for determining the placement parameters' robustness. The performance and the comparison of results provided by the tool compared with real world data is demonstrated using two specimens.},
}
@article{p841,
  journal = {IEEE TVCG},
  year = 2010,
  title = {World Lines},
  doi = {10.1109/TVCG.2010.223},
  url = {http://dx.doi.org/10.1109/TVCG.2010.223},
  author = {Waser, J. and Fuchs, R. and Ribicic, H. and Schindler, B. and Bloschl, G. and Groller, E.},
  pages = {1458--1467},
  keywords = {Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics},
  abstract = {In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.},
}
@article{p941,
  journal = {IEEE TVCG},
  year = 2009,
  title = {A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete},
  doi = {10.1109/TVCG.2009.115},
  url = {http://dx.doi.org/10.1109/TVCG.2009.115},
  author = {Fritz, L. and Hadwiger, M. and Geier, G. and Pittino, G. and Groller, E.},
  pages = {1343--1350},
  keywords = {Non-Destructive Testing, Multi-Dimensional Transfer Functions, Direction Visualization, Volume Rendering},
  abstract = {This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.},
}
@article{p945,
  journal = {IEEE TVCG},
  year = 2009,
  title = {BrainGazer - Visual Queries for Neurobiology Research},
  doi = {10.1109/TVCG.2009.121},
  url = {http://dx.doi.org/10.1109/TVCG.2009.121},
  author = {Bruckner, S. and Solteszova, V. and Groller, E. and Hladuvka, J. and Buhler, K. and Yu, J.Y. and Dickson, B.J.},
  pages = {1497--1504},
  keywords = {Biomedical visualization, neurobiology, visual queries, volume visualization},
  abstract = {Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.},
}
@article{p988,
  journal = {IEEE TVCG},
  year = 2009,
  title = {Visual Human+Machine Learning},
  doi = {10.1109/TVCG.2009.199},
  url = {http://dx.doi.org/10.1109/TVCG.2009.199},
  author = {Fuchs, R. and Waser, J. and Groller, E.},
  pages = {1327--1334},
  keywords = {Interactive Visual Analysis, Volumetric Data, Multiple Competing Hypotheses, Knowledge Discovery, Computerassisted Multivariate Data Exploration, Curse of Dimensionality, Predictive Analysis, Genetic Algorithm},
  abstract = {In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.},
}
@article{p1106,
  journal = {IEEE TVCG},
  year = 2008,
  title = {The Seismic Analyzer: Interpreting and Illustrating 2D Seismic Data},
  doi = {10.1109/TVCG.2008.170},
  url = {http://dx.doi.org/10.1109/TVCG.2008.170},
  author = {Patel, D. and Giertsen, C. and Thurmond, J. and Gjelberg, J. and Groller, E.},
  pages = {1571--1578},
  keywords = {Seismic interpretation, Illustrative rendering, Seismic attributes, Top-down interpretation},
  abstract = {We present a toolbox for quickly interpreting and illustrating 2D slices of seismic volumetric reflection data. Searching for oil and gas involves creating a structural overview of seismic reflection data to identify hydrocarbon reservoirs. We improve the search of seismic structures by precalculating the horizon structures of the seismic data prior to interpretation. We improve the annotation of seismic structures by applying novel illustrative rendering algorithms tailored to seismic data, such as deformed texturing and line and texture transfer functions. The illustrative rendering results in multi-attribute and scale invariant visualizations where features are represented clearly in both highly zoomed in and zoomed out views. Thumbnail views in combination with interactive appearance control allows for a quick overview of the data before detailed interpretation takes place. These techniques help reduce the work of seismic illustrators and interpreters.},
}
@article{p1112,
  journal = {IEEE TVCG},
  year = 2008,
  title = {Visualization of Myocardial Perfusion Derived from Coronary Anatomy},
  doi = {10.1109/TVCG.2008.180},
  url = {http://dx.doi.org/10.1109/TVCG.2008.180},
  author = {Termeer, M. and Bescos, J.O. and Breeuwer, M. and Vilanova, A. and Gerritsen, F. and Groller, E. and Nagel, E.},
  pages = {1595--1602},
  keywords = {Cardiac visualization, coronary artery territories, myocardial perfusion},
  abstract = {Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.},
}
@article{p1199,
  journal = {IEEE TVCG},
  year = 2007,
  title = {CoViCAD: Comprehensive Visualization of Coronary Artery Disease},
  doi = {10.1109/TVCG.2007.70550},
  url = {http://dx.doi.org/10.1109/TVCG.2007.70550},
  author = {Termeer, M. and Bescos, J.O. and Breeuwer, M. and Vilanova, A. and Gerritsen, F. and Groller, E.},
  pages = {1632--1639},
  keywords = {Cardiac MRI, late enhancement, viability, bull's eye plot},
  abstract = {We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.},
}
@article{p1204,
  journal = {IEEE TVCG},
  year = 2007,
  title = {Enhancing Depth-Perception with Flexible Volumetric Halos},
  doi = {10.1109/TVCG.2007.70555},
  url = {http://dx.doi.org/10.1109/TVCG.2007.70555},
  author = {Bruckner, S. and Groller, E.},
  pages = {1344--1351},
  keywords = {Volume rendering, illustrative visualization, halos},
  abstract = {Volumetric data commonly has high depth complexity which makes it difficult to judge spatial relationships accurately. There are many different ways to enhance depth perception, such as shading, contours, and shadows. Artists and illustrators frequently employ halos for this purpose. In this technique, regions surrounding the edges of certain structures are darkened or brightened which makes it easier to judge occlusion. Based on this concept, we present a flexible method for enhancing and highlighting structures of interest using GPU-based direct volume rendering. Our approach uses an interactively defined halo transfer function to classify structures of interest based on data value, direction, and position. A feature-preserving spreading algorithm is applied to distribute seed values to neighboring locations, generating a controllably smooth field of halo intensities. These halo intensities are then mapped to colors and opacities using a halo profile function. Our method can be used to annotate features at interactive frame rates.},
}
@article{p1226,
  journal = {IEEE TVCG},
  year = 2007,
  title = {Semantic Layers for Illustrative Volume Rendering},
  doi = {10.1109/TVCG.2007.70591},
  url = {http://dx.doi.org/10.1109/TVCG.2007.70591},
  author = {Rautek, P. and Bruckner, S. and Groller, E.},
  pages = {1336--1343},
  keywords = {Illustrative Visualization, Focus+Context Techniques, Volume Visualization},
  abstract = {Direct volume rendering techniques map volumetric attributes (e.g., density, gradient magnitude, etc.) to visual styles. Commonly this mapping is specified by a transfer function. The specification of transfer functions is a complex task and requires expert knowledge about the underlying rendering technique. In the case of multiple volumetric attributes and multiple visual styles the specification of the multi-dimensional transfer function becomes more challenging and non-intuitive. We present a novel methodology for the specification of a mapping from several volumetric attributes to multiple illustrative visual styles. We introduce semantic layers that allow a domain expert to specify the mapping in the natural language of the domain. A semantic layer defines the mapping of volumetric attributes to one visual style. Volumetric attributes and visual styles are represented as fuzzy sets. The mapping is specified by rules that are evaluated with fuzzy logic arithmetics. The user specifies the fuzzy sets and the rules without special knowledge about the underlying rendering technique. Semantic layers allow for a linguistic specification of the mapping from attributes to visual styles replacing the traditional transfer function specification.},
}
@article{p1230,
  journal = {IEEE TVCG},
  year = 2007,
  title = {Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT},
  doi = {10.1109/TVCG.2007.70598},
  url = {http://dx.doi.org/10.1109/TVCG.2007.70598},
  author = {Heinzl, C. and Kastner, J. and Groller, E.},
  pages = {1520--1527},
  keywords = {DECT image fusion, local surface extraction, Dual Energy CT, metrology, dimensional measurement, variance comparison},
  abstract = {This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.},
}
@article{p1335,
  journal = {IEEE TVCG},
  year = 2006,
  title = {Caricaturistic Visualization},
  doi = {10.1109/TVCG.2006.123},
  url = {http://dx.doi.org/10.1109/TVCG.2006.123},
  author = {Rautek, P. and Viola, I. and Groller, E.},
  pages = {1085--1092},
  keywords = {Illustrative Visualization, Focus+Context Techniques, Volume Visualization},
  abstract = {Caricatures are pieces of art depicting persons or sociological conditions in a non-veridical way. In both cases caricatures are referring to a reference model. The deviations from the reference model are the characteristic features of the depicted subject. Good caricatures exaggerate the characteristics of a subject in order to accent them. The concept of caricaturistic visualization is based on the caricature metaphor. The aim of caricaturistic visualization is an illustrative depiction of characteristics of a given dataset by exaggerating deviations from the reference model. We present the general concept of caricaturistic visualization as well as a variety of examples. We investigate different visual representations for the depiction of caricatures. Further, we present the caricature matrix, a technique to make differences between datasets easily identifiable},
}
@article{p1345,
  journal = {IEEE TVCG},
  year = 2006,
  title = {Exploded Views for Volume Data},
  doi = {10.1109/TVCG.2006.140},
  url = {http://dx.doi.org/10.1109/TVCG.2006.140},
  author = {Bruckner, S. and Groller, E.},
  pages = {1077--1084},
  keywords = {Illustrative visualization, exploded views, volume rendering},
  abstract = {Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second},
}
@article{p1355,
  journal = {IEEE TVCG},
  year = 2006,
  title = {Importance-Driven Focus of Attention},
  doi = {10.1109/TVCG.2006.152},
  url = {http://dx.doi.org/10.1109/TVCG.2006.152},
  author = {Viola, I. and Feixas, M. and Sbert, M. and Groller, E.},
  pages = {933--940},
  keywords = {Illustrative visualization, volume visualization, interacting with volumetric datasets, characteristic viewpoint estimation, focus+context techniques},
  abstract = {This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views},
}
@inproceedings{p1388,
  booktitle = {Proc. InfoVis},
  year = 2005,
  title = {A sky dome visualisation for identification of astronomical orientations},
  doi = {10.1109/INFVIS.2005.1532123},
  url = {http://dx.doi.org/10.1109/INFVIS.2005.1532123},
  author = {Zotti, G. and Groller, E.},
  pages = {8--15},
  keywords = { Archaeology, Astronomy, data mining},
  abstract = {It has long been known that ancient temples were frequently oriented along the cardinal directions or to certain points along the horizon where Sun or Moon rise or set on special days of the year. In the last decades, archaeologists have found evidence of even older building structures buried in the soil, with doorways that also appear to have distinct orientations. This paper presents a novel diagram combining archaeological maps with a folded-apart, flattened view of the whole sky, showing the local horizon and the daily paths of Sun, Moon and brighter stars. By use of this diagram, interesting groupings of astronomical orientation directions, e.g. to certain Sunrise and Sunset points could be identified, which were evidently used to mark certain days of the year. Orientations to a few significant stars very likely indicated the beginning of the agricultural year in the middle neolithic period},
}
@inproceedings{p1466,
  booktitle = {Proc. Vis},
  year = 2005,
  title = {Profile Flags: a novel metaphor for probing of T<sub>2</sub> maps},
  doi = {10.1109/VISUAL.2005.1532847},
  url = {http://dx.doi.org/10.1109/VISUAL.2005.1532847},
  author = {Mlejnek, M. and Ermest, P. and Vilanova, A. and van der Rijt, R. and van den Bosch, H. and Gerritsen, F. and Groller, E.},
  pages = {599--606},
  keywords = {visualization in medicine, applications of visualization},
  abstract = {This paper describes a tool for the visualization of T2 maps of knee cartilage. Given the anatomical scan, and the T2 map of the cartilage, we combine the information on the shape and the quality of the cartilage in a single image. The Profile Flag is an intuitive 3D glyph for probing and annotating of the underlying data. It comprises a bulletin board pin-like shape with a small flag on top of it. While moving the glyph along the reconstructed surface of an object, the curve data measured along the pin's needle and in its neighborhood are shown on the flag. The application area of the Profile Flag is manifold, enabling the visualization of profile data of dense but in-homogeneous objects. Furthermore, it extracts the essential part of the data without removing or even reducing the context information. By sticking Profile Flags into the investigated structure, one or more significant locations can be annotated by showing the local characteristics of the data at that locations. In this paper we are demonstrating the properties of the tool by visualizing T2 maps of knee cartilage.},
}
@inproceedings{p1506,
  booktitle = {Proc. Vis},
  year = 2005,
  title = {VolumeShop: an interactive system for direct volume illustration},
  doi = {10.1109/VISUAL.2005.1532856},
  url = {http://dx.doi.org/10.1109/VISUAL.2005.1532856},
  author = {Bruckner, S. and Groller, E.},
  pages = {671--678},
  keywords = {illustrative visualization, volume rendering, focus+context techniques},
  abstract = {Illustrations play a major role in the education process. Whether used to teach a surgical or radiologic procedure, to illustrate normal or aberrant anatomy, or to explain the functioning of a technical device, illustration significantly impacts learning. Although many specimens are readily available as volumetric data sets, particularly in medicine, illustrations are commonly produced manually as static images in a time-consuming process. Our goal is to create a fully dynamic three-dimensional illustration environment which directly operates on volume data. Single images have the aesthetic appeal of traditional illustrations, but can be interactively altered and explored. In this paper we present methods to realize such a system which combines artistic visual styles and expressive visualization techniques. We introduce a novel concept for direct multi-object volume visualization which allows control of the appearance of inter-penetrating objects via two-dimensional transfer functions. Furthermore, a unifying approach to efficiently integrate many non-photorealistic rendering models is presented. We discuss several illustrative concepts which can be realized by combining cutaways, ghosting, and selective deformation. Finally, we also propose a simple interface to specify objects of interest through three-dimensional volumetric painting. All presented methods are integrated into VolumeShop, an interactive hardware-accelerated application for direct volume illustration.},
}
@inproceedings{p1606,
  booktitle = {Proc. Vis},
  year = 2004,
  title = {Importance-driven volume rendering},
  doi = {10.1109/VISUAL.2004.48},
  url = {http://dx.doi.org/10.1109/VISUAL.2004.48},
  author = {Viola, I. and Kanitsar, A. and Groller, E.},
  pages = {139--145},
  keywords = {view-dependent visualization, volume rendering, focus+context techniques, level-of-detail techniques, non-photorealistic techniques},
  abstract = {This work introduces importance-driven volume rendering as a novel technique for automatic focus and context display of volumetric data. Our technique is a generalization of cut-away views, which - depending on the viewpoint - remove or suppress less important parts of a scene to reveal more important underlying information. We automatize and apply this idea to volumetric data. Each part of the volumetric data is assigned an object importance, which encodes visibility priority. This property determines which structures should be readily discernible and which structures are less important. In those image regions, where an object occludes more important structures it is displayed more sparsely than in those areas where no occlusion occurs. Thus the objects of interest are clearly visible. For each object several representations, i.e., levels of sparseness, are specified. The display of an individual object may incorporate different levels of sparseness. The goal is to emphasize important structures and to maximize the information content in the final image. This work also discusses several possible schemes for level of sparseness specification and different ways how object importance can be composited to determine the final appearance of a particular object.},
}
@inproceedings{p1613,
  booktitle = {Proc. Vis},
  year = 2004,
  title = {Interactive thickness visualization of articular cartilage},
  doi = {10.1109/VISUAL.2004.56},
  url = {http://dx.doi.org/10.1109/VISUAL.2004.56},
  author = {Mlejnek, M. and Vilanova, A. and Groller, E.},
  pages = {521--527},
  keywords = {visualization in medicine, applications of visualization},
  abstract = {This work describes a method to visualize the thickness of curved thin objects. Given the MRI volume data of articular cartilage, medical doctors investigate pathological changes of the thickness. Since the tissue is very thin, it is impossible to reliably map the thickness information by direct volume rendering. Our idea is based on unfolding of such structures preserving their thickness. This allows to perform anisotropic geometrical operations (e.g., scaling the thickness). However, flattening of a curved structure implies a distortion of its surface. The distortion problem is alleviated through a focus-and-context minimization approach. Distortion is smallest close to a focal point which can be interactively selected by the user.},
}
@inproceedings{p1628,
  booktitle = {Proc. Vis},
  year = 2004,
  title = {Non-linear model fitting to parameterize diseased blood vessels},
  doi = {10.1109/VISUAL.2004.72},
  url = {http://dx.doi.org/10.1109/VISUAL.2004.72},
  author = {La Cruz, A. and Straka, M. and Kochl, A. and Sramek, M. and Groller, E. and Fleischmann, D.},
  pages = {393--400},
  keywords = {Visualization, Segmentation, Blood Vessel Detection},
  abstract = {Accurate estimation of vessel parameters is a prerequisite for automated visualization and analysis of healthy and diseased blood vessels. The objective of this research is to estimate the dimensions of lower extremity arteries, imaged by computed tomography (CT). These parameters are required to get a good quality visualization of healthy as well as diseased arteries using a visualization technique such as curved planar reformation (CPR). The vessel is modeled using an elliptical or cylindrical structure with specific dimensions, orientation and blood vessel mean density. The model separates two homogeneous regions: its inner side represents a region of density for vessels, and its outer side a region for background. Taking into account the point spread function (PSF) of a CT scanner, a function is modeled with a Gaussian kernel, in order to smooth the vessel boundary in the model. A new strategy for vessel parameter estimation is presented. It stems from vessel model and model parameter optimization by a nonlinear optimization procedure, i.e., the Levenberg-Marquardt technique. The method provides center location, diameter and orientation of the vessel as well as blood and background mean density values. The method is tested on synthetic data and real patient data with encouraging results.},
}
@inproceedings{p1656,
  booktitle = {Proc. Vis},
  year = 2004,
  title = {The VesselGlyph: focus & context visualization in CT-angiography},
  doi = {10.1109/VISUAL.2004.104},
  url = {http://dx.doi.org/10.1109/VISUAL.2004.104},
  author = {Straka, M. and Cervenansky, M. and La Cruz, A. and Kochl, A. and Sramek, M. and Groller, E. and Fleischmann, D.},
  pages = {385--392},
  keywords = {focus & context technique, direct volume rendering, curved planar reformation, vessel visualization},
  abstract = {Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.},
}
@inproceedings{p1725,
  booktitle = {Proc. Vis},
  year = 2003,
  title = {Advanced curved planar reformation: flattening of vascular structures},
  doi = {10.1109/VISUAL.2003.1250353},
  url = {http://dx.doi.org/10.1109/VISUAL.2003.1250353},
  author = {Kanitsar, A. and Wegenkittl, R. and Fleischmann, D. and Groller, E.},
  pages = {43--50},
  keywords = {computed tomography angiography, vessel analysis, curved planar reformation},
  abstract = {Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.},
}
@inproceedings{p1743,
  booktitle = {Proc. Vis},
  year = 2003,
  title = {Hardware-based nonlinear filtering and segmentation using high-level shading languages},
  doi = {10.1109/VISUAL.2003.1250387},
  url = {http://dx.doi.org/10.1109/VISUAL.2003.1250387},
  author = {Viola, I. and Kanitsar, A. and Groller, E.},
  pages = {309--316},
  keywords = { Non-linear Filtering, Segmentation, Hardware Acceleration},
  abstract = {Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.},
}
@inproceedings{p1812,
  booktitle = {Proc. InfoVis},
  year = 2002,
  title = {Process visualization with levels of detail},
  doi = {10.1109/INFVIS.2002.1173149},
  url = {http://dx.doi.org/10.1109/INFVIS.2002.1173149},
  author = {Matkovic, K. and Hauser, H. and Sainitzer, R. and Groller, E.},
  pages = {67--70},
  keywords = {process visualization, information visualization, levels of detail, focus+context visualization},
  abstract = {We demonstrate how we apply information visualization techniques to process monitoring. Virtual instruments are enhanced using history encoding instruments are capable of displaying the current value and the value from the near past. Multi-instruments are capable of displaying several data sources simultaneously. Levels of detail for virtual instruments are introduced where the screen area is inversely proportional to the information amount displayed. Furthermore the monitoring system is enhanced by using: 3D anchoring attachment of instruments to positions on a 3D model, collision avoidance a physically based spring model prevents instruments from overlapping, and focus+context rendering - giving the user a possibility to examine particular instruments in detail without loosing the context information.},
}
@inproceedings{p1843,
  booktitle = {Proc. Vis},
  year = 2002,
  title = {Christmas tree case study: computed tomography as a tool for mastering complex real world objects with applications in computer graphics},
  doi = {10.1109/VISUAL.2002.1183812},
  url = {http://dx.doi.org/10.1109/VISUAL.2002.1183812},
  author = {Kanitsar, A. and Theussl, T. and Mroz, L. and Sramek, M. and Bartroli, A.V. and Csebfalvi, B. and Hladuvka, J. and Fleischmann, D. and Knapp, M. and Wegenkittl, R. and Felkel, P. and Rottger, S. and Guthe, S. and Purgathofer, W. and Groller, E.},
  pages = {489--492},
  keywords = {modeling, computed tomography, volume visualization},
  abstract = {We report on using computed tomography (CT) as a model acquisition tool for complex objects in computer graphics. Unlike other modeling and scanning techniques the complexity of the object is irrelevant in CT, which naturally enables to model objects with, for example, concavities, holes, twists or fine surface details. Once the data is scanned, one can apply post-processing techniques for data enhancement, modification or presentation. For demonstration purposes we chose to scan a Christmas tree which exhibits high complexity which is difficult or even impossible to handle with other techniques. However, care has to be taken to achieve good scanning results with CT. Further, we illustrate post-processing by means of data segmentation and photorealistic as well as non-photorealistic surface and volume rendering techniques.},
}
@inproceedings{p1847,
  booktitle = {Proc. Vis},
  year = 2002,
  title = {CPR - curved planar reformation},
  doi = {10.1109/VISUAL.2002.1183754},
  url = {http://dx.doi.org/10.1109/VISUAL.2002.1183754},
  author = {Kanitsar, A. and Fleischmann, D. and Wegenkittl, R. and Felkel, P. and Groller, E.},
  pages = {37--44},
  keywords = {computed tomography angiography, vessel analysis, curved planar reformation},
  abstract = {Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.},
}
@inproceedings{p1946,
  booktitle = {Proc. Vis},
  year = 2001,
  title = {Computed tomography angiography: a case study of peripheral vessel investigation},
  doi = {10.1109/VISUAL.2001.964555},
  url = {http://dx.doi.org/10.1109/VISUAL.2001.964555},
  author = {Kanitsar, A. and Fleischmann, D. and Wegenkittl, R. and Sandner, D. and Felkel, P. and Groller, E.},
  pages = {477--480},
  keywords = {Computed Tomography Angiography (CTA), semi automatic segmentation, optimal path computation},
  abstract = {This paper deals with vessel exploration based on computed tomography angiography. Large image sequences of the lower extremities are investigated in a clinical environment. Two different approaches for peripheral vessel diagnosis dealing with stenosis and calcification detection are introduced. The paper presents an automated vessel-tracking tool for curved planar reformation. An interactive segmentation tool for bone removal is proposed.},
}
@inproceedings{p1964,
  booktitle = {Proc. Vis},
  year = 2001,
  title = {Nonlinear virtual colon unfolding},
  doi = {10.1109/VISUAL.2001.964540},
  url = {http://dx.doi.org/10.1109/VISUAL.2001.964540},
  author = {Vilanova Bartroli, A.V. and Wegenkittl, R. and Konig, A. and Groller, E.},
  pages = {411--418},
  keywords = {Volume Rendering, Virtual Endoscopy},
  abstract = {The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.},
}
@inproceedings{p1967,
  booktitle = {Proc. Vis},
  year = 2001,
  title = {Optimal regular volume sampling},
  doi = {10.1109/VISUAL.2001.964498},
  url = {http://dx.doi.org/10.1109/VISUAL.2001.964498},
  author = {Theussl, T. and MÃ¶ller, T. and Groller, E.},
  pages = {91--98},
  keywords = {volume data,Cartesiangrid,close packing,hexagonal sampling, body centered cubic},
  abstract = {The classification of volumetric data sets as well as their rendering algorithms are typically based on the representation of the underlying grid. Grid structures based on a Cartesian lattice are the de-facto standard for regular representations of volumetric data. In this paper we introduce a more general concept of regular grids for the representation of volumetric data. We demonstrate that a specific type of regular lattice-the so-called body-centered cubic-is able to represent the same data set as a Cartesian grid to the same accuracy but with 29.3% fewer samples. This speeds up traditional volume rendering algorithms by the same ratio, which we demonstrate by adopting a splatting implementation for these new lattices. We investigate different filtering methods required for computing the normals on this lattice. The lattice representation results also in lossless compression ratios that are better than previously reported. Although other regular grid structures achieve the same sample efficiency, the body-centered cubic is particularly easy to use. The only assumption necessary is that the underlying volume is isotropic and band-limited-an assumption that is valid for most practical data sets.},
}
@inproceedings{p2063,
  booktitle = {Proc. Vis},
  year = 2000,
  title = {Mastering interactive surface rendering for Java-based diagnostic applications},
  doi = {10.1109/VISUAL.2000.885726},
  url = {http://dx.doi.org/10.1109/VISUAL.2000.885726},
  author = {Mroz, L. and Wegenkittl, R. and Groller, E.},
  pages = {437--440},
  keywords = {volume visualization, surface rendering, medical applications, tomographic data},
  abstract = {The display of iso-surfaces in medical data sets is an important visualization technique used by radiologists for the diagnosis of volumetric density data sets. The demands put by radiologists on such a display technique are interactivity, multiple stacked transparent surfaces and cutting planes that allow an interactive clipping of the surfaces. This paper presents a Java based, platform independent implementation of a very fast surface rendering algorithm which combines the advantages of explicit surface representation, splatting, and shear-warp projection to fulfill all these requirements. The algorithm is implemented within the context of J-Vision, an application for viewing and diagnosing medical images which is currently in use at various hospitals.},
}
@inproceedings{p2064,
  booktitle = {Proc. Vis},
  year = 2000,
  title = {Mastering interactive virtual bronchioscopy on a low-end PC},
  doi = {10.1109/VISUAL.2000.885732},
  url = {http://dx.doi.org/10.1109/VISUAL.2000.885732},
  author = {Wegenkittl, R. and Vilanova, A. and Hegedust, B. and Wagner, D. and Freund, M.C. and Groller, E.},
  pages = {461--464},
  keywords = {medical visualization, virtual endoscopy, visualization system},
  abstract = {Virtual endoscopy presents the cross-sectional acquired 3D-data of a computer tomograph as an endoluminal view. The common approach for the visualization of a virtual endoscopy is surface rendering, yielding images close to a real endoscopy. If external structures are of interest, volume rendering techniques have to be used. These methods do not display the exact shape of the inner lumen very well. For certain applications, e.g. operation planning of a transbronchial biopsy, both the shape of the inner lumen as well as outer structures like blood vessels and the tumor have to be delineated. A method is described, that allows a quick and easy hybrid visualization using overlays of different visualization methods like different surfaces or volume renderings with different transfer functions in real time on a low-end PC. To achieve real time frame rates, image based rendering techniques have been used.},
}
@inproceedings{p2091,
  booktitle = {Proc. Vis},
  year = 2000,
  title = {Two-level volume rendering - fusing MIP and DVR},
  doi = {10.1109/VISUAL.2000.885697},
  url = {http://dx.doi.org/10.1109/VISUAL.2000.885697},
  author = {Hauser, H. and Mroz, L. and Bischi, G.-I. and Groller, E.},
  pages = {211--218},
  keywords = {visualization, volume rendering, dynamical systems,medical applications},
  abstract = {Presents a two-level approach for fusing direct volume rendering (DVR) and maximum-intensity projection (MIP) within a joint rendering method. Different structures within the data set are rendered locally by either MIP or DVR on an object-by-object basis. Globally, all the results of subsequent object renderings are combined in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data, while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus-and-context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates.},
}
@inproceedings{p2264,
  booktitle = {Proc. Vis},
  year = 1998,
  title = {Real-time techniques for 3D flow visualization},
  doi = {10.1109/VISUAL.1998.745317},
  url = {http://dx.doi.org/10.1109/VISUAL.1998.745317},
  author = {Fuhrmann, A. and Groller, E.},
  pages = {305--312},
  keywords = {virtual environments, flow visualization, texturing, interaction, magic lens, focussing},
  abstract = {Visualization of three-dimensional steady flow has to overcome a lot of problems to be effective. Among them are occlusion of distant details, lack of directional and depth hints and occlusion. We present methods which address these problems for real-time graphic representations applicable in virtual environments. We use dashtubes, i.e., animated, opacity-mapped streamlines, as a visualization icon for 3D-flow visualization. We present a texture mapping technique to keep the level of texture detail along a streamline nearly constant even when the velocity of the flow varies considerably. An algorithm is described which distributes the dashtubes evenly in space. We apply magic lenses and magic boxes as interaction techniques for investigating densely filled areas without overwhelming the observer with visual detail. Implementation details of these methods and their integration in our virtual environment conclude the paper.},
}
@inproceedings{p2336,
  booktitle = {Proc. Vis},
  year = 1997,
  title = {Fast oriented line integral convolution for vector field visualization via the Internet},
  doi = {10.1109/VISUAL.1997.663897},
  url = {http://dx.doi.org/10.1109/VISUAL.1997.663897},
  author = {Wegenkittl, R. and Groller, E.},
  pages = {309--316},
  keywords = {},
  abstract = {Oriented line integral convolution (OLIC) illustrates flow fields by convolving a sparse texture with an anisotropic convolution kernel. The kernel is aligned to the underlying flow of the vector field. OLIC does not only show the direction of the flow but also its orientation. The paper presents fast rendering of oriented line integral convolution (FROLIC), which is approximately two orders of magnitude faster than OLIC. Costly convolution operations as done in OLIC are replaced in FROLIC by approximating a streamlet through a set of disks with varying intensity. The issue of overlapping streamlets is discussed. Two efficient animation techniques for animating FROLIC images are described. FROLIC has been implemented as a Java applet. This allows researchers from various disciplines (typically with inhomogenous hardware environments) to conveniently explore and investigate analytically defined 2D vector fields.},
}
@inproceedings{p2377,
  booktitle = {Proc. Vis},
  year = 1997,
  title = {Visualizing the behaviour of higher dimensional dynamical systems},
  doi = {10.1109/VISUAL.1997.663867},
  url = {http://dx.doi.org/10.1109/VISUAL.1997.663867},
  author = {Wegenkittl, R. and Loffelmann, H. and Groller, E.},
  pages = {119--125},
  keywords = {},
  abstract = {In recent years scientific visualization has been driven by the need to visualize high-dimensional data sets within high-dimensional spaces. However most visualization methods are designed to show only some statistical features of the data set. The paper deals with the visualization of trajectories of high-dimensional dynamical systems which form a L n n data set of a smooth n-dimensional flow. Three methods that are based on the idea of parallel coordinates are presented and discussed. Visualizations done with these new methods are shown and an interactive visualization tool for the exploration of high-dimensional dynamical systems is proposed.},
}
